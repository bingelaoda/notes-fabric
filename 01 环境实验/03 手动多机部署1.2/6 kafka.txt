#### kafka安装 
--192.168.2.121
1 下载kafka 
wget http://mirror.bit.edu.cn/apache/kafka/1.1.1/kafka_2.12-1.1.1.tgz
tar -xvf kafka_2.12-1.1.1.tgz
cd kafka_2.12-1.1.1/



2 安装java
yum install -y java-1.8.0-openjdk
java -version
#openjdk version "1.8.0_181"


3 修改config/server.properties
-------------------------- 文件末尾加入
advertised.listeners=PLAINTEXT://kafka0:9092

# 默认为false
unclean.leader.election.enable = false     

# 根据kafka的节点数设置，需要小于备份数
# 意思完成了“指定数量”的备份后，写入才返回成功
min.insync.replicas = 1                    

# 数据备份数
default.replication.factor = 1             

# 需要大于创世块中设置的 Orderer.AbsoluteMaxBytes
# 注意不要超过 socket.request.max.bytes(100M)
# 这里设置的是10M
message.max.bytes = 10000120                
                                           
# 需要大于创世块中设置的 Orderer.AbsoluteMaxBytes
# 注意不要超过 socket.request.max.bytes(100M)
# 这里设置的是10M
replica.fetch.max.bytes = 10485760

                                           
# 当前orderer不支持kafka log，需要关闭这个功能
log.retention.ms = -1                      
-------------------------- 
cd ~/soft/kafka_2.12-1.1.1

## 启动kafka(单节点模式)
1 启动kafka自带的zookeeper
./bin/zookeeper-server-start.sh config/zookeeper.properties 

2 启动kafka
./bin/kafka-server-start.sh config/server.properties


## 测试kafka
1 创建名为`test`的topic
./bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test


2 查看topic
./bin/kafka-topics.sh --list --zookeeper localhost:2181


3 启动生产者，并输入任意字符
./bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test


4 启动消费者，接收到生产者的输入
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning




#### fabric 集成kafka

## 基础准备
1 修改configtx.yaml中Orderer
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Orderer: &OrdererDefaults
     OrdererType: kafka
     Addresses:
         - orderer0.member1.example.com:7050
     BatchTimeout: 2s
     BatchSize:
         MaxMessageCount: 10
         AbsoluteMaxBytes: 8 MB         # 注意要小于kafka中设置的10M
         PreferredMaxBytes: 512 KB
     MaxChannels: 0
     Kafka:
         Brokers:
             - kafka0 :9092       # 可以填入多个kafka节点的地址

^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

2  如果kafka配置了tls加密，
还要修改修改每个orderer的配置文件orderer.yaml中的Kakfa部分的内容，并上传证书。




## 重新部署

1 修改hosts
--192.168.2.120
--192.168.2.121
--192.168.2.122
--192.168.2.123
^^^^^^^^^^^^^^
192.168.2.200 kafka0
^^^^^^^^^^^^^^


2 清理历史数据
--192.168.2.120
--192.168.2.121
--192.168.2.122
--192.168.2.123
rm -rf /opt/app/fabric/peer/data

--192.168.2.120
rm -rf /opt/app/fabric/orderer/data


3 重新生成创世区块
--192.168.2.120
cd ~/fabric-deploy/
rm -rf genesisblock
./bin/configtxgen -profile TwoOrgsOrdererGenesis -outputBlock ./genesisblock  -channelID genesis
scp genesisblock root@192.168.2.120:/opt/app/fabric/orderer/


4 启动节点
--192.168.2.120
cd /opt/app/fabric/orderer/
./startorder.sh &
cd /opt/app/fabric/peer
./startpeer.sh &


--192.168.2.121
--192.168.2.122
--192.168.2.123 
cd /opt/app/fabric/peer
./startpeer.sh &





5 查看节点状态
cd ~/fabric-deploy/Admin@org1.example.com/
./useAdmin0Org1.sh node status
./useAdmin1Org1.sh node status

cd ~/fabric-deploy/Admin@org2.example.com/
./useAdmin0Org2.sh node status
./useAdmin1Org2.sh node status

cd ~/fabric-deploy/User1@org1.example.com/
./useUser0Org1.sh node status
./useUser1Org1.sh node status

cd ~/fabric-deploy/User1@org2.example.com/
./useUser0Org2.sh node status
./useUser1Org2.sh node status



#### 创建channel
cd ~/fabric-deploy/


--生成channel文件
 ./bin/configtxgen -profile TwoOrgsChannel -outputCreateChannelTx mychannel.tx -channelID mychannel


--为每个组织的peer生成anchor
./bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate Org1MSPanchors.tx -channelID mychannel -asOrg Org1MSP
./bin/configtxgen -profile TwoOrgsChannel -outputAnchorPeersUpdate Org2MSPanchors.tx -channelID mychannel -asOrg Org2MSP

--将验证orderer.example.com的根证书复制到用户目录
cp certs/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem  Admin\@org1.example.com/
cp certs/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem  User1\@org1.example.com/
cp certs/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem  Admin\@org2.example.com/
cp certs/ordererOrganizations/example.com/tlsca/tlsca.example.com-cert.pem  User1\@org2.example.com/



cd  Admin\@org1.example.com
--创建channel
./useAdmin0Org1.sh channel create -o orderer.example.com:7050 -c mychannel -f ../mychannel.tx --tls true --cafile tlsca.example.com-cert.pem
--将peer加入channel
./useAdmin0Org1.sh channel join -b mychannel.block
./useAdmin1Org1.sh channel join -b mychannel.block
./useAdmin0Org1.sh channel list
./useAdmin1Org1.sh channel list
./useAdmin0Org1.sh channel update -o orderer.example.com:7050 -c mychannel -f ../Org1MSPanchors.tx --tls true --cafile ./tlsca.example.com-cert.pem
--拷贝 mychannel.block 到 org2
cp mychannel.block ../Admin\@org2.example.com/
cd ..





cd  Admin\@org2.example.com
--将peer加入channel
./useAdmin0Org2.sh channel join -b mychannel.block
./useAdmin1Org2.sh channel join -b mychannel.block
./useAdmin0Org2.sh channel list
./useAdmin1Org2.sh channel list
./useAdmin0Org2.sh channel update -o orderer.example.com:7050 -c mychannel -f ../Org2MSPanchors.tx --tls true --cafile ./tlsca.example.com-cert.pem
cd ..






6 合约部署
见 [ 4 合约调度 ]
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ hello

#### cp hello 合约代码到 gohome目录下
/home/gopath/src/github.com/hyperledger



####  合约安装
cd ~/fabric-deploy/


--合约打包
cd Admin\@org1.example.com/
./useAdmin0Org1.sh chaincode package helloworld-pack.out -n helloworld -v 0.0.1 -s -S -p github.com/hyperledger/fabric/chaincode/go/helloworld/cmd
./useAdmin0Org1.sh chaincode signpackage helloworld-pack.out signed-helloworld-pack.out
--安装合约
./useAdmin0Org1.sh chaincode install ./signed-helloworld-pack.out
--查看已安装合约
./useAdmin0Org1.sh chaincode list   --installed
--安装合约
./useAdmin1Org1.sh chaincode install ./signed-helloworld-pack.out
--查看已安装合约
./useAdmin1Org1.sh chaincode list   --installed
--复制到org2
cp signed-helloworld-pack.out  ../Admin\@org2.example.com/




cd ../Admin\@org2.example.com/
--安装合约
./useAdmin0Org2.sh chaincode install ./signed-helloworld-pack.out
--查看已安装合约
./useAdmin0Org2.sh chaincode list   --installed
--安装合约
./useAdmin1Org2.sh chaincode install ./signed-helloworld-pack.out
--查看已安装合约
./useAdmin1Org2.sh chaincode list   --installed




####  合约初始化
--合约初始化（需要且只需要进行一次初始化，只能由签署合约的用户进行初始化）
cd Admin\@org1.example.com/
./useAdmin0Org1.sh chaincode instantiate -o orderer.example.com:7050 --tls true --cafile ./tlsca.example.com-cert.pem -C mychannel -n helloworld -v 0.0.1 -c '{"Args":["a","helloworld!!!"]}' -P "OR('Org1MSP.member','Org2MSP.member')"

--
Error: could not assemble transaction, err Proposal response was not successful, error code 500, msg plugin with name escc could not be used: plugin with name escc wasn't found
原因：1.1 版本 非1.2版本

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 

####  合约调用
--合约调用（更新）
cd Admin\@org2.example.com/
./useAdmin0Org2.sh chaincode invoke -o orderer.example.com:7050  --tls true --cafile ./tlsca.example.com-cert.pem -C mychannel -n helloworld -c '{"Args":["set","a","helloworld-good!!!"]}'
./useAdmin1Org2.sh chaincode invoke -o orderer.example.com:7050  --tls true --cafile ./tlsca.example.com-cert.pem -C mychannel -n helloworld -c '{"Args":["set","b","test"]}'
./useAdmin0Org2.sh chaincode invoke -o orderer.example.com:7050  --tls true --cafile ./tlsca.example.com-cert.pem -C mychannel -n helloworld -c '{"Args":["set","c","abc"]}'
./useAdmin1Org2.sh chaincode invoke -o orderer.example.com:7050  --tls true --cafile ./tlsca.example.com-cert.pem -C mychannel -n helloworld -c '{"Args":["set","d","abcdef"]}'


--合约调用2

cd Admin\@org1.example.com/
./useAdmin0Org1.sh chaincode query -C mychannel -n helloworld -c '{"Args":["query","a"]}'
./useAdmin1Org1.sh chaincode query -C mychannel -n helloworld -c '{"Args":["query","a"]}'
./useAdmin1Org1.sh chaincode query -C mychannel -n helloworld -c '{"Args":["query","b"]}'


cd Admin\@org2.example.com/
./useAdmin0Org2.sh chaincode query -C mychannel -n helloworld -c '{"Args":["query","a"]}'
./useAdmin1Org2.sh chaincode query -C mychannel -n helloworld -c '{"Args":["query","b"]}'


cd User1\@org1.example.com/
./useUser0Org1.sh chaincode query -C mychannel -n helloworld -c '{"Args":["query","a"]}'
./useUser1Org1.sh chaincode query -C mychannel -n helloworld -c '{"Args":["query","a"]}'

cd User1\@org2.example.com/
./useUser0Org2.sh chaincode query -C mychannel -n helloworld -c '{"Args":["query","a"]}'
./useUser1Org2.sh chaincode query -C mychannel -n helloworld -c '{"Args":["query","a"]}'




------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ demo





## kafka观察
cd ~/soft/kafka_2.12-1.1.1

1 创建channel 观察kafka中topic
bin/kafka-topics.sh --list --zookeeper localhost:2181
genesis:重启时创建
mychannel:创建子链时创建 

./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic genesis --from-beginning
./bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic mychannel --from-beginning

2 清空kafka和zk数据
rm -rf /tmp/zookeeper/
rm -rf /tmp/kafka-logs/

3 删除topic
bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic genesis
bin/kafka-topics.sh --delete --zookeeper localhost:2181 --topic mychannel



------------------------------------------
#创建channel ./useAdmin0Org1.sh channel create -o orderer.example.com:7050 -c mychannel -f ../mychannel.tx --tls true --cafile tlsca.example.com-cert.pem
2018-11-01 01:54:27.819 CST [common/configtx] addToMap -> DEBU 1f9 Adding to config map: [Value]  /Channel/Consortium
2018-11-01 01:54:27.819 CST [orderer/common/broadcast] Handle -> WARN 1fa [channel: mychannel] Rejecting broadcast of config message from 192.168.2.120:38366 because of error: error authorizing update: error validating ReadSet: readset expected key [Group]  /Channel/Application at version 0, but got version 1
2018-11-01 01:54:27.819 CST [orderer/common/server] func1 -> DEBU 1fb Closing Broadcast stream
2018-11-01 01:54:27.822 CST [common/deliver] Handle -> WARN 1fc Error reading from 192.168.2.120:38364: rpc error: code = Canceled desc = context canceled
2018-11-01 01:54:27.822 CST [orderer/common/server] func1 -> DEBU 1fd Closing Deliver stream

-- 解决 kafka删除重新安装


