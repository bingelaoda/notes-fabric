#broker的全局唯一的编号，不可以重复
broker.id=0

#用来监听链接的端口，producer或者consumer将在此端口建立连接
port=9092

#处理网络请求的线程数量 
num.network.threads=3

#用来处理磁盘Io的线程数量
num.io.threads=8

#发送套接字的缓冲区大小
socket.send.buffer.bytes=102400

#接受套接字的缓冲区的大小
socket.receive.buffer.bytes=102400

#请求套接字的缓冲区大小 
socket.request.max.bytes=104857600


############################# Log Basics #############################

# A comma separated list of directories under which to store log files
log.dirs=/tmp/kafka-logs

#topic在当前broker上的分片个数
num.partitions=2

#用来恢复和清理data下数据的线程数量
num.recovery.threads.per.data.dir=1

############################# Internal Topic Settings  #############################
# The replication factor for the group metadata internal topics "__consumer_offsets" and "__transaction_state"
# For anything other than development testing, a value greater than 1 is recommended for to ensure availability such as 3.
offsets.topic.replication.factor=1
transaction.state.log.replication.factor=1
transaction.state.log.min.isr=1

############################# Log  Policy #############################
#segment文件保留的最长时间，超时将被删除
log.retention.hours=168  

#滚动生成新的segment文件的最大时间
log.roll.hours=168

#topic的分区是以一堆segment文件存储的，这个控制每个segment的大小，会被topic创建时的指定参数覆盖
log.segment.bytes=1073741824  

#文件大小检查的周期时间，是否处罚 log.cleanup.policy中设置的策略
log.retention.check.interval.ms=60000 



# A size-based retention policy for logs. Segments are pruned from the log unless the remaining
# segments drop below log.retention.bytes. Functions independently of log.retention.hours.
#log.retention.bytes=1073741824

# The maximum size of a log segment file. When this size is reached a new log segment will be created.
log.segment.bytes=1073741824

# The interval at which log segments are checked to see if they can be deleted according
# to the retention policies
log.retention.check.interval.ms=300000


#是否开启日志清理 
log.cleaner.enable=false


############################# Zookeeper #############################
#zookeeper集群的地址，可以是多个，多个之间用逗号分割 hostname1:port1,hostname2:port2,hostname3:port3
#zookeeper.connect=localhost:2181  
zookeeper.connect=zk1:12181,zk2:12181,zk3:12181

#ZooKeeper的连接超时时间
zookeeper.connection.timeout.ms=1000000


############################# Group Coordinator Settings #############################

# The following configuration specifies the time, in milliseconds, that the GroupCoordinator will delay the initial consumer rebalance.
# The rebalance will be further delayed by the value of group.initial.rebalance.delay.ms as new members join the group, up to a maximum of max.poll.interval.ms.
# The default value for this is 3 seconds.
# We override this to 0 here as it makes for a better out-of-the-box experience for development and testing.
# However, in production environments the default value of 3 seconds is more suitable as this will help to avoid unnecessary, and potentially expensive, rebalances during application startup.
group.initial.rebalance.delay.ms=0






# 默认为false
unclean.leader.election.enable = false     

# 根据kafka的节点数设置，需要小于备份数
# 意思完成了“指定数量”的备份后，写入才返回成功
min.insync.replicas = 1                    

# 数据备份数
default.replication.factor = 1             

# 需要大于创世块中设置的 Orderer.AbsoluteMaxBytes
# 注意不要超过 socket.request.max.bytes(100M)
# 这里设置的是10M
message.max.bytes = 10000120                
                                           
# 需要大于创世块中设置的 Orderer.AbsoluteMaxBytes
# 注意不要超过 socket.request.max.bytes(100M)
# 这里设置的是10M
replica.fetch.max.bytes = 10485760

                                           
# 当前orderer不支持kafka log，需要关闭这个功能
# @2018-07-29 08:19:32
log.retention.ms = -1

#支持数据删除
delete.topic.enable=true

